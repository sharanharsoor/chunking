"""
Comprehensive CLI tests for Token-based Chunker.

This module tests command-line interface functionality specifically
for the token-based chunking strategy with various configurations.
"""

import pytest
import subprocess
import sys
import json
import tempfile
import shutil
from pathlib import Path


class TestTokenBasedCLI:
    """CLI tests for Token-based Chunker."""

    @pytest.fixture(autouse=True)
    def setup(self):
        """Set up test environment."""
        self.test_data_dir = Path("test_data")
        self.temp_dir = Path(tempfile.mkdtemp())

        # Ensure test data exists
        if not self.test_data_dir.exists():
            pytest.skip("Test data directory not found")

        yield

        # Cleanup
        if self.temp_dir.exists():
            shutil.rmtree(self.temp_dir)

    def _get_cli_command(self):
        """Get the CLI command to use."""
        # Try different ways to invoke the CLI
        possible_commands = [
            [sys.executable, "-m", "chunking_strategy.cli"],
            [sys.executable, "-m", "chunking_strategy"],
            ["chunking-strategy"],
        ]
        return possible_commands[0]  # Use the first option

    def test_cli_help_and_version(self):
        """Test CLI help and version commands."""
        print(f"\nüß™ Testing CLI help and version...")

        cmd_base = self._get_cli_command()

        # Test help command
        try:
            result = subprocess.run(
                cmd_base + ["--help"],
                capture_output=True,
                text=True,
                timeout=30
            )

            print(f"   Help command exit code: {result.returncode}")
            if result.returncode != 0:
                print(f"   stderr: {result.stderr}")
                print(f"   stdout: {result.stdout}")
                pytest.skip("CLI help command not working, skipping CLI tests")
            else:
                print(f"   ‚úÖ Help command working")
                assert "chunking" in result.stdout.lower() or "usage" in result.stdout.lower()

        except subprocess.TimeoutExpired:
            pytest.skip("CLI command timed out, skipping CLI tests")
        except FileNotFoundError:
            pytest.skip("CLI command not found, skipping CLI tests")

    def test_basic_cli_chunking(self):
        """Test basic CLI chunking with token-based strategy."""
        print(f"\nüîß Testing basic CLI chunking...")

        # Create a test input file
        test_content = """
        This is a test document for CLI chunking with the token-based strategy.
        The CLI should be able to process this content and create appropriate chunks
        based on token boundaries. This content has enough tokens to create multiple
        chunks when configured with smaller token limits.
        """

        input_file = self.temp_dir / "test_input.txt"
        output_file = self.temp_dir / "cli_output.json"

        with open(input_file, 'w') as f:
            f.write(test_content)

        cmd = self._get_cli_command() + [
            "chunk",
            str(input_file),
            "--strategy", "token_based",
            "--tokens-per-chunk", "30",
            "--tokenizer-type", "simple",
            "--output", str(output_file),
            "--format", "json"
        ]

        try:
            result = subprocess.run(
                cmd,
                capture_output=True,
                text=True,
                timeout=60
            )

            print(f"   Command: {' '.join(cmd)}")
            print(f"   Exit code: {result.returncode}")

            if result.returncode != 0:
                print(f"   stderr: {result.stderr}")
                print(f"   stdout: {result.stdout}")
                pytest.skip(f"CLI chunking failed: {result.stderr}")

            # Check if output file was created
            if output_file.exists():
                with open(output_file, 'r') as f:
                    output_data = json.load(f)

                print(f"   ‚úÖ Output file created")
                print(f"   Chunks created: {len(output_data.get('chunks', []))}")

                # Validate output structure
                assert "chunks" in output_data
                assert "strategy_used" in output_data
                assert output_data.get("strategy_used") == "token_based"
                assert len(output_data["chunks"]) > 0

                # Check chunk metadata
                first_chunk = output_data["chunks"][0]
                assert "content" in first_chunk
                assert "metadata" in first_chunk

                if "extra" in first_chunk["metadata"]:
                    assert "token_count" in first_chunk["metadata"]["extra"]
                    assert "tokenizer_type" in first_chunk["metadata"]["extra"]

                print(f"   ‚úÖ CLI chunking successful with {len(output_data['chunks'])} chunks")
            else:
                pytest.skip("CLI output file not created")

        except subprocess.TimeoutExpired:
            pytest.skip("CLI command timed out")
        except Exception as e:
            pytest.skip(f"CLI test error: {e}")

    def test_cli_with_different_tokenizers(self):
        """Test CLI with different tokenizer options."""
        print(f"\nüî¨ Testing CLI with different tokenizers...")

        test_content = "This is a tokenizer test with multiple words and sentences."
        input_file = self.temp_dir / "tokenizer_test.txt"

        with open(input_file, 'w') as f:
            f.write(test_content)

        tokenizer_configs = [
            {
                "name": "Simple",
                "args": ["--tokenizer-type", "simple"],
                "expected_tokens": len(test_content.split())
            },
            {
                "name": "TikToken GPT-3.5",
                "args": ["--tokenizer-type", "tiktoken", "--tokenizer-model", "gpt-3.5-turbo"],
                "expected_tokens": None  # Will vary
            }
        ]

        for config in tokenizer_configs:
            print(f"   Testing {config['name']}...")

            output_file = self.temp_dir / f"output_{config['name'].lower().replace(' ', '_')}.json"

            cmd = self._get_cli_command() + [
                "chunk",
                str(input_file),
                "--strategy", "token_based",
                "--tokens-per-chunk", "50"
            ] + config["args"] + [
                "--output", str(output_file),
                "--format", "json"
            ]

            try:
                result = subprocess.run(
                    cmd,
                    capture_output=True,
                    text=True,
                    timeout=30
                )

                if result.returncode == 0 and output_file.exists():
                    with open(output_file, 'r') as f:
                        output_data = json.load(f)

                    total_tokens = output_data.get("source_info", {}).get("total_tokens", 0)
                    print(f"      ‚úÖ {config['name']}: {total_tokens} tokens, {len(output_data.get('chunks', []))} chunks")

                    assert output_data.get("strategy_used") == "token_based"
                    assert len(output_data.get("chunks", [])) > 0

                else:
                    print(f"      ‚ö†Ô∏è  {config['name']}: Failed or not available")
                    if result.stderr:
                        print(f"         Error: {result.stderr[:100]}...")

            except subprocess.TimeoutExpired:
                print(f"      ‚ö†Ô∏è  {config['name']}: Timeout")
            except Exception as e:
                print(f"      ‚ö†Ô∏è  {config['name']}: Error - {e}")

    def test_cli_with_configuration_file(self):
        """Test CLI with configuration file input."""
        print(f"\n‚öôÔ∏è  Testing CLI with configuration file...")

        # Create a configuration file
        config_content = {
            "strategies": {
                "primary": "token_based"
            },
            "token_based": {
                "tokens_per_chunk": 100,
                "overlap_tokens": 10,
                "tokenizer_type": "simple",
                "preserve_word_boundaries": True
            }
        }

        config_file = self.temp_dir / "token_config.yaml"

        # Write YAML manually to avoid dependency
        yaml_content = f"""
strategies:
  primary: token_based

token_based:
  tokens_per_chunk: 100
  overlap_tokens: 10
  tokenizer_type: simple
  preserve_word_boundaries: true
"""

        with open(config_file, 'w') as f:
            f.write(yaml_content.strip())

        # Test input
        test_content = "Configuration file test. " * 20  # 60 words
        input_file = self.temp_dir / "config_test.txt"
        output_file = self.temp_dir / "config_output.json"

        with open(input_file, 'w') as f:
            f.write(test_content)

        cmd = self._get_cli_command() + [
            "chunk",
            str(input_file),
            "--config", str(config_file),
            "--output", str(output_file),
            "--format", "json"
        ]

        try:
            result = subprocess.run(
                cmd,
                capture_output=True,
                text=True,
                timeout=30
            )

            print(f"   Config file command exit code: {result.returncode}")

            if result.returncode == 0 and output_file.exists():
                with open(output_file, 'r') as f:
                    output_data = json.load(f)

                print(f"   ‚úÖ Configuration file processed successfully")
                print(f"   Strategy used: {output_data.get('strategy_used')}")
                print(f"   Chunks created: {len(output_data.get('chunks', []))}")

                assert output_data.get("strategy_used") == "token_based"
                assert len(output_data.get("chunks", [])) > 0

                # Verify configuration was applied
                if "source_info" in output_data:
                    config_applied = output_data["source_info"].get("tokens_per_chunk_config")
                    if config_applied:
                        assert config_applied == 100  # From config file

            else:
                print(f"   ‚ö†Ô∏è  Configuration file test failed")
                if result.stderr:
                    print(f"   stderr: {result.stderr}")
                pytest.skip("Configuration file CLI test failed")

        except subprocess.TimeoutExpired:
            pytest.skip("Configuration CLI command timed out")
        except Exception as e:
            pytest.skip(f"Configuration CLI test error: {e}")

    def test_cli_batch_processing(self):
        """Test CLI batch processing of multiple files."""
        print(f"\nüì¶ Testing CLI batch processing...")

        # Create multiple test files
        test_files = []
        for i in range(3):
            content = f"Test file {i+1} content. " * 10  # 30 words each
            file_path = self.temp_dir / f"batch_test_{i+1}.txt"
            with open(file_path, 'w') as f:
                f.write(content)
            test_files.append(file_path)

        output_dir = self.temp_dir / "batch_output"
        output_dir.mkdir()

        # Test batch processing
        cmd = self._get_cli_command() + [
            "batch",
            str(self.temp_dir),
            "--pattern", "batch_test_*.txt",
            "--strategy", "token_based",
            "--tokens-per-chunk", "20",
            "--tokenizer-type", "simple",
            "--output-dir", str(output_dir),
            "--format", "json"
        ]

        try:
            result = subprocess.run(
                cmd,
                capture_output=True,
                text=True,
                timeout=60
            )

            print(f"   Batch command exit code: {result.returncode}")

            if result.returncode == 0:
                # Check if output files were created
                output_files = list(output_dir.glob("*.json"))
                print(f"   ‚úÖ Batch processing completed")
                print(f"   Output files created: {len(output_files)}")

                if len(output_files) >= len(test_files):
                    # Verify one of the output files
                    sample_output = output_files[0]
                    with open(sample_output, 'r') as f:
                        output_data = json.load(f)

                    assert output_data.get("strategy_used") == "token_based"
                    assert len(output_data.get("chunks", [])) > 0

                    print(f"   ‚úÖ Batch processing successful")
                else:
                    print(f"   ‚ö†Ô∏è  Expected {len(test_files)} files, got {len(output_files)}")
                    pytest.skip("Batch processing incomplete")
            else:
                print(f"   ‚ö†Ô∏è  Batch processing failed")
                if result.stderr:
                    print(f"   stderr: {result.stderr}")
                pytest.skip("Batch processing CLI test failed")

        except subprocess.TimeoutExpired:
            pytest.skip("Batch CLI command timed out")
        except Exception as e:
            pytest.skip(f"Batch CLI test error: {e}")

    def test_cli_parameter_validation(self):
        """Test CLI parameter validation."""
        print(f"\n‚úÖ Testing CLI parameter validation...")

        input_file = self.temp_dir / "validation_test.txt"
        with open(input_file, 'w') as f:
            f.write("Test content for parameter validation.")

        # Test invalid parameters
        invalid_configs = [
            {
                "name": "Invalid tokens per chunk",
                "args": ["--tokens-per-chunk", "0"],
                "should_fail": True
            },
            {
                "name": "Invalid overlap",
                "args": ["--tokens-per-chunk", "10", "--overlap-tokens", "15"],
                "should_fail": True
            },
            {
                "name": "Invalid tokenizer",
                "args": ["--tokenizer-type", "invalid_tokenizer"],
                "should_fail": True
            },
            {
                "name": "Valid parameters",
                "args": ["--tokens-per-chunk", "50", "--overlap-tokens", "5"],
                "should_fail": False
            }
        ]

        for config in invalid_configs:
            print(f"   Testing {config['name']}...")

            output_file = self.temp_dir / f"validation_{config['name'].replace(' ', '_')}.json"

            cmd = self._get_cli_command() + [
                "chunk",
                str(input_file),
                "--strategy", "token_based"
            ] + config["args"] + [
                "--output", str(output_file),
                "--format", "json"
            ]

            try:
                result = subprocess.run(
                    cmd,
                    capture_output=True,
                    text=True,
                    timeout=30
                )

                if config["should_fail"]:
                    if result.returncode != 0:
                        print(f"      ‚úÖ {config['name']}: Correctly failed")
                    else:
                        print(f"      ‚ö†Ô∏è  {config['name']}: Should have failed but didn't")
                else:
                    if result.returncode == 0:
                        print(f"      ‚úÖ {config['name']}: Correctly succeeded")
                    else:
                        print(f"      ‚ö†Ô∏è  {config['name']}: Should have succeeded")
                        if result.stderr:
                            print(f"         Error: {result.stderr}")

            except subprocess.TimeoutExpired:
                print(f"      ‚ö†Ô∏è  {config['name']}: Timeout")
            except Exception as e:
                print(f"      ‚ö†Ô∏è  {config['name']}: Error - {e}")

    def test_cli_with_real_files(self):
        """Test CLI with real files from test_data."""
        print(f"\nüìÅ Testing CLI with real files...")

        # Find a text file in test_data
        text_files = list(self.test_data_dir.glob("*.txt"))
        if not text_files:
            pytest.skip("No text files found in test_data")

        test_file = text_files[0]  # Use first available text file
        output_file = self.temp_dir / f"real_file_output.json"

        print(f"   Processing file: {test_file.name}")

        cmd = self._get_cli_command() + [
            "chunk",
            str(test_file),
            "--strategy", "token_based",
            "--tokens-per-chunk", "200",
            "--overlap-tokens", "20",
            "--tokenizer-type", "simple",
            "--output", str(output_file),
            "--format", "json"
        ]

        try:
            result = subprocess.run(
                cmd,
                capture_output=True,
                text=True,
                timeout=60
            )

            print(f"   Command exit code: {result.returncode}")

            if result.returncode == 0 and output_file.exists():
                with open(output_file, 'r') as f:
                    output_data = json.load(f)

                file_size = test_file.stat().st_size
                chunks_created = len(output_data.get("chunks", []))
                total_tokens = output_data.get("source_info", {}).get("total_tokens", 0)

                print(f"   ‚úÖ Real file processed successfully")
                print(f"   File size: {file_size} bytes")
                print(f"   Total tokens: {total_tokens}")
                print(f"   Chunks created: {chunks_created}")

                assert output_data.get("strategy_used") == "token_based"
                assert chunks_created > 0
                assert total_tokens > 0

                # Verify chunk structure
                if chunks_created > 0:
                    first_chunk = output_data["chunks"][0]
                    assert "content" in first_chunk
                    assert "metadata" in first_chunk
                    assert len(first_chunk["content"]) > 0

            else:
                print(f"   ‚ö†Ô∏è  Real file processing failed")
                if result.stderr:
                    print(f"   stderr: {result.stderr}")
                pytest.skip("Real file CLI test failed")

        except subprocess.TimeoutExpired:
            pytest.skip("Real file CLI command timed out")
        except Exception as e:
            pytest.skip(f"Real file CLI test error: {e}")

    def test_cli_output_formats(self):
        """Test different CLI output formats."""
        print(f"\nüìã Testing CLI output formats...")

        test_content = "Output format test content with multiple words and sentences."
        input_file = self.temp_dir / "format_test.txt"

        with open(input_file, 'w') as f:
            f.write(test_content)

        output_formats = ["json", "yaml", "csv"]

        for format_type in output_formats:
            print(f"   Testing {format_type.upper()} format...")

            output_file = self.temp_dir / f"format_test.{format_type}"

            cmd = self._get_cli_command() + [
                "chunk",
                str(input_file),
                "--strategy", "token_based",
                "--tokens-per-chunk", "30",
                "--tokenizer-type", "simple",
                "--output", str(output_file),
                "--format", format_type
            ]

            try:
                result = subprocess.run(
                    cmd,
                    capture_output=True,
                    text=True,
                    timeout=30
                )

                if result.returncode == 0 and output_file.exists():
                    file_size = output_file.stat().st_size
                    print(f"      ‚úÖ {format_type.upper()}: {file_size} bytes created")

                    # Basic validation that file has content
                    assert file_size > 0

                    # For JSON, verify structure
                    if format_type == "json":
                        with open(output_file, 'r') as f:
                            data = json.load(f)
                        assert "chunks" in data
                        assert "strategy_used" in data
                        assert data["strategy_used"] == "token_based"
                else:
                    print(f"      ‚ö†Ô∏è  {format_type.upper()}: Failed")
                    if result.stderr:
                        print(f"         Error: {result.stderr[:100]}...")

            except subprocess.TimeoutExpired:
                print(f"      ‚ö†Ô∏è  {format_type.upper()}: Timeout")
            except Exception as e:
                print(f"      ‚ö†Ô∏è  {format_type.upper()}: Error - {e}")


if __name__ == "__main__":
    # Run the tests directly
    pytest.main([__file__, "-v", "-s"])
