"""
Comprehensive integration test suite for the chunking strategy library.

Tests all major functionality including:
- All chunking strategies
- Hardware detection and optimization
- Batch processing capabilities
- PDF and document processing
- CLI functionality
- Error handling and edge cases
- Performance characteristics
"""

import os
import tempfile
import time
import json
from pathlib import Path
from typing import List, Dict, Any
import pytest

from chunking_strategy import (
    create_chunker,
    list_chunkers,
    ChunkerOrchestrator,
    __version__
)
from chunking_strategy.core.batch import BatchProcessor
from chunking_strategy.core.hardware import get_hardware_info
from chunking_strategy.core.metrics import ChunkingQualityEvaluator


class TestComprehensiveIntegration:
    """Comprehensive integration tests covering all library functionality."""

    @pytest.fixture(autouse=True)
    def setup(self):
        """Set up test environment."""
        self.test_data_dir = Path("test_data")
        self.temp_dir = Path(tempfile.mkdtemp())

        # Ensure test data exists
        if not self.test_data_dir.exists():
            pytest.skip("Test data directory not found")

        yield

        # Cleanup
        import shutil
        if self.temp_dir.exists():
            shutil.rmtree(self.temp_dir)

    def test_all_chunkers_registration(self):
        """Test that all chunkers are properly registered."""
        chunkers = list_chunkers()

        # Check that we have the core chunkers (always expected)
        core_chunkers = [
            "fixed_size",
            "sentence_based",
            "paragraph_based"
        ]

        for expected in core_chunkers:
            assert expected in chunkers, f"Core chunker {expected} not registered"

        # PDF chunker is conditional based on dependencies
        try:
            import PyMuPDF
            pdf_available = True
        except ImportError:
            try:
                import PyPDF2
                pdf_available = True
            except ImportError:
                try:
                    import pdfminer
                    pdf_available = True
                except ImportError:
                    pdf_available = False

        if pdf_available:
            assert "pdf_chunker" in chunkers, "PDF chunker should be registered when PDF libraries are available"
        else:
            # PDF chunker should not be registered without dependencies
            print("PDF chunker not registered due to missing dependencies - this is expected")

        # Test that we can create each chunker
        for chunker_name in chunkers:
            try:
                chunker = create_chunker(chunker_name)
                assert chunker is not None
                assert hasattr(chunker, 'chunk')
                assert hasattr(chunker, 'name')
                assert chunker.name == chunker_name
            except Exception as e:
                pytest.fail(f"Failed to create chunker {chunker_name}: {e}")

    def test_text_chunking_strategies(self):
        """Test all text-based chunking strategies."""
        test_file = self.test_data_dir / "sample_article.txt"
        if not test_file.exists():
            pytest.skip("Sample article test file not found")

        strategies = ["fixed_size", "sentence_based", "paragraph_based"]

        for strategy in strategies:
            chunker = create_chunker(strategy)
            result = chunker.chunk(test_file)

            # Basic validation
            assert len(result.chunks) > 0, f"No chunks generated by {strategy}"
            assert result.processing_time is not None
            assert result.strategy_used == strategy

            # Content validation
            for chunk in result.chunks:
                assert chunk.content is not None
                assert len(chunk.content.strip()) > 0
                assert chunk.id is not None
                assert chunk.metadata is not None
                assert chunk.modality is not None

    def test_pdf_processing_comprehensive(self):
        """Test PDF processing with multiple backends."""
        pdf_file = self.test_data_dir / "example.pdf"
        if not pdf_file.exists():
            pytest.skip("PDF test file not found")

        # Test with different backends
        backends = ["auto", "pymupdf", "pypdf2", "pdfminer"]

        for backend in backends:
            try:
                chunker = create_chunker(
                    "pdf_chunker",
                    backend=backend,
                    pages_per_chunk=1
                )

                result = chunker.chunk(pdf_file)

                # Validation
                assert len(result.chunks) > 0, f"No chunks from PDF with {backend}"
                assert result.processing_time is not None

                # Check chunk types
                chunk_types = set()
                for chunk in result.chunks:
                    chunk_type = chunk.metadata.extra.get('chunk_type', 'unknown')
                    chunk_types.add(chunk_type)

                assert 'text' in chunk_types, f"No text chunks from {backend}"

                # PyMuPDF should extract images if available
                if backend in ["auto", "pymupdf"]:
                    # Check if images were detected (may or may not be present)
                    pass

            except ImportError:
                # Skip if backend dependencies not available
                pytest.skip(f"Backend {backend} dependencies not available")
            except Exception as e:
                pytest.fail(f"PDF processing failed with {backend}: {e}")

    def test_universal_document_chunker(self):
        """Test the universal document chunker with Tika."""
        try:
            chunker = create_chunker("universal_document")
        except Exception:
            pytest.skip("Universal document chunker not available (missing Tika)")

        # Test with different file types
        test_files = [
            "sample_article.txt",
            "pytorch_readme.md",
            "example.pdf"
        ]

        for file_name in test_files:
            test_file = self.test_data_dir / file_name
            if not test_file.exists():
                continue

            try:
                result = chunker.chunk(test_file)
                assert len(result.chunks) > 0, f"No chunks from {file_name}"

                # Check metadata
                assert result.source_info is not None
                assert 'extraction_method' in result.source_info

            except Exception as e:
                # Log but don't fail - some files might not be processable
                print(f"Warning: Universal chunker failed on {file_name}: {e}")

    def test_hardware_detection(self):
        """Test hardware detection functionality."""
        try:
            hardware_info = get_hardware_info()

            # Basic validation
            assert hardware_info.cpu_count > 0
            assert hardware_info.recommended_batch_size > 0
            assert hardware_info.recommended_workers > 0
            assert hardware_info.platform is not None
            assert hardware_info.architecture is not None

            # Memory info should be available
            if hardware_info.memory_total_gb:
                assert hardware_info.memory_total_gb > 0

        except ImportError:
            pytest.skip("Hardware detection dependencies not available")

    def test_batch_processing_modes(self):
        """Test all batch processing modes."""
        try:
            from chunking_strategy.core.batch import BatchProcessor
        except ImportError:
            pytest.skip("Batch processing dependencies not available")

        # Get test files
        test_files = list(self.test_data_dir.glob("*.txt"))[:3]  # Limit to 3 files
        if len(test_files) < 2:
            pytest.skip("Not enough test files for batch processing")

        processor = BatchProcessor()
        modes = ["sequential", "thread", "process"]

        for mode in modes:
            try:
                result = processor.process_files(
                    files=test_files,
                    default_strategy="fixed_size",
                    default_params={"chunk_size": 500},
                    parallel_mode=mode,
                    workers=2 if mode != "sequential" else 1
                )

                # Validation
                assert result.total_files == len(test_files)
                assert len(result.successful_files) > 0
                assert result.total_chunks > 0
                assert result.total_processing_time is not None

            except Exception as e:
                pytest.fail(f"Batch processing failed in {mode} mode: {e}")

    def test_orchestrator_yaml_config(self):
        """Test orchestrator with YAML configuration."""
        # Create a simple test config
        config_data = {
            'strategies': {
                'primary': 'fixed_size',
                'fallbacks': ['sentence_based'],
                'configs': {
                    'fixed_size': {'chunk_size': 800}
                }
            },
            'preprocessing': {'enabled': True},
            'postprocessing': {'enabled': True}
        }

        config_file = self.temp_dir / "test_config.yaml"
        import yaml
        with open(config_file, 'w') as f:
            yaml.dump(config_data, f)

        # Test orchestrator
        orchestrator = ChunkerOrchestrator(config_path=config_file)

        test_file = self.test_data_dir / "short.txt"
        if test_file.exists():
            result = orchestrator.chunk_file(test_file)
            assert len(result.chunks) > 0
            assert result.strategy_used in ['fixed_size', 'sentence_based']

    def test_quality_metrics_evaluation(self):
        """Test quality metrics evaluation."""
        test_file = self.test_data_dir / "sample_article.txt"
        if not test_file.exists():
            pytest.skip("Sample article test file not found")

        chunker = create_chunker("sentence_based", max_sentences=3)
        result = chunker.chunk(test_file)

        try:
            evaluator = ChunkingQualityEvaluator()
            metrics = evaluator.evaluate(result.chunks)

            # Validation
            assert metrics.size_consistency >= 0.0
            assert metrics.size_consistency <= 1.0
            assert metrics.coherence >= 0.0
            assert metrics.coherence <= 1.0
            assert metrics.coverage >= 0.0
            assert metrics.coverage <= 1.0

        except Exception as e:
            # Quality evaluation might fail on some systems
            print(f"Warning: Quality evaluation failed: {e}")

    def test_error_handling_edge_cases(self):
        """Test error handling for various edge cases."""

        # Test with non-existent file (use Path object to force file access)
        with pytest.raises((FileNotFoundError, ValueError)):
            chunker = create_chunker("fixed_size")
            from pathlib import Path
            chunker.chunk(Path("non_existent_file.txt"))

        # Test with empty content
        chunker = create_chunker("fixed_size")
        result = chunker.chunk("")
        # Should handle gracefully (may return empty or minimal chunks)
        assert result is not None

        # Test with very large chunk size
        chunker = create_chunker("fixed_size", chunk_size=1000000)
        test_file = self.test_data_dir / "short.txt"
        if test_file.exists():
            result = chunker.chunk(test_file)
            assert result is not None

        # Test with invalid strategy name - registry returns None for non-existent strategies
        chunker = create_chunker("non_existent_strategy")
        assert chunker is None, "Should return None for non-existent strategy"

    def test_performance_characteristics(self):
        """Test performance characteristics of chunkers."""
        test_file = self.test_data_dir / "alice_wonderland.txt"
        if not test_file.exists():
            pytest.skip("Large test file not found")

        strategies = ["fixed_size", "sentence_based"]
        performance_data = {}

        for strategy in strategies:
            chunker = create_chunker(strategy)

            start_time = time.time()
            result = chunker.chunk(test_file)
            processing_time = time.time() - start_time

            performance_data[strategy] = {
                'chunks': len(result.chunks),
                'time': processing_time,
                'chunks_per_second': len(result.chunks) / processing_time if processing_time > 0 else 0
            }

            # Basic performance expectations
            assert processing_time < 30.0, f"{strategy} took too long: {processing_time}s"
            assert len(result.chunks) > 0, f"No chunks generated by {strategy}"

        # Log performance data for analysis
        print(f"Performance data: {performance_data}")

    def test_cli_integration(self):
        """Test CLI functionality."""
        import subprocess
        import sys

        # Test list-strategies command
        try:
            result = subprocess.run([
                sys.executable, "-m", "chunking_strategy.cli", "list-strategies"
            ], capture_output=True, text=True, timeout=30)

            assert result.returncode == 0, f"list-strategies failed: {result.stderr}"
            assert "fixed_size" in result.stdout

        except subprocess.TimeoutExpired:
            pytest.skip("CLI test timed out")
        except Exception as e:
            pytest.skip(f"CLI test failed: {e}")

        # Test hardware command if dependencies available
        try:
            result = subprocess.run([
                sys.executable, "-m", "chunking_strategy.cli", "hardware"
            ], capture_output=True, text=True, timeout=30)

            if result.returncode == 0:
                assert "CPU" in result.stdout or "Hardware" in result.stdout

        except (subprocess.TimeoutExpired, Exception):
            # Hardware detection might not be available
            pass

    def test_memory_usage_large_files(self):
        """Test memory usage with large files."""
        test_file = self.test_data_dir / "alice_wonderland.txt"
        if not test_file.exists():
            pytest.skip("Large test file not found")

        # Test with different chunk sizes
        chunk_sizes = [500, 1000, 2000]

        for chunk_size in chunk_sizes:
            chunker = create_chunker("fixed_size", chunk_size=chunk_size)

            # Monitor basic performance
            start_time = time.time()
            result = chunker.chunk(test_file)
            processing_time = time.time() - start_time

            assert processing_time < 60.0, f"Processing took too long with chunk_size={chunk_size}"
            assert len(result.chunks) > 0, f"No chunks with chunk_size={chunk_size}"

            # Validate chunk sizes are approximately correct
            chunk_lengths = [len(chunk.content) for chunk in result.chunks]
            avg_length = sum(chunk_lengths) / len(chunk_lengths)

            # Allow some variance but should be roughly the target size
            assert avg_length < chunk_size * 2, f"Average chunk too large: {avg_length}"

    def test_concurrent_processing(self):
        """Test concurrent processing capabilities."""
        import threading
        import concurrent.futures

        # Filter out empty files for this test
        test_files = [f for f in self.test_data_dir.glob("*.txt")
                     if f.exists() and f.stat().st_size > 0][:3]
        if len(test_files) < 2:
            pytest.skip("Not enough non-empty test files for concurrent processing")

        def process_file(file_path):
            chunker = create_chunker("fixed_size", chunk_size=1000)
            return chunker.chunk(file_path)

        # Test concurrent processing
        with concurrent.futures.ThreadPoolExecutor(max_workers=3) as executor:
            futures = [executor.submit(process_file, f) for f in test_files]
            results = [future.result(timeout=30) for future in futures]

        # Validation
        assert len(results) == len(test_files)
        for result in results:
            assert len(result.chunks) > 0, f"Expected chunks but got none for {result.source_info}"
            assert result.processing_time is not None

    def test_document_files_comprehensive_compatibility(self):
        """Test comprehensive compatibility with various document formats including .doc files."""

        # Look for document files in test_data
        document_extensions = ['.doc', '.pdf', '.rtf']
        document_files = {}

        for ext in document_extensions:
            files = list(self.test_data_dir.glob(f"*{ext}"))
            if files:
                document_files[ext] = files[0]  # Use the first file found

        if not document_files:
            pytest.skip("No document files (.doc, .pdf, .rtf) found in test_data")

        print(f"\nðŸ“„ Testing document file compatibility:")
        print(f"Available formats: {list(document_files.keys())}")

        # Test strategies that should work with document files
        test_strategies = [
            "fixed_size",
            "sentence_based",
            "paragraph_based"
        ]

        # Add doc_chunker if available
        if "doc_chunker" in list_chunkers():
            test_strategies.append("doc_chunker")

        results = {}

        for file_ext, file_path in document_files.items():
            results[file_ext] = {}
            print(f"\n  Testing {file_ext} file: {file_path.name}")

            for strategy in test_strategies:
                try:
                    chunker = create_chunker(strategy)
                    if chunker is None:
                        results[file_ext][strategy] = {"status": "UNAVAILABLE"}
                        continue

                    # Test chunking
                    start_time = time.time()
                    result = chunker.chunk(str(file_path))
                    processing_time = time.time() - start_time

                    # Handle both ChunkingResult and list return types
                    if hasattr(result, 'chunks'):
                        chunks = result.chunks
                    else:
                        chunks = result

                    if chunks and len(chunks) > 0:
                        # Quality checks
                        total_content = sum(len(str(chunk.content if hasattr(chunk, 'content') else chunk).strip())
                                          for chunk in chunks)

                        results[file_ext][strategy] = {
                            "status": "SUCCESS",
                            "chunk_count": len(chunks),
                            "total_content_length": total_content,
                            "processing_time": processing_time
                        }

                        print(f"    âœ… {strategy}: {len(chunks)} chunks, {total_content} chars, {processing_time:.3f}s")

                        # Performance check - should complete within reasonable time
                        assert processing_time < 60, f"{strategy} took too long ({processing_time:.2f}s) for {file_ext}"

                        # Content check - should extract meaningful content
                        assert total_content > 10, f"{strategy} extracted too little content ({total_content} chars) from {file_ext}"

                    else:
                        results[file_ext][strategy] = {"status": "NO_CHUNKS"}
                        print(f"    âš ï¸  {strategy}: No chunks produced")

                except Exception as e:
                    error_msg = str(e)

                    # Check for dependency errors (should be skipped, not failed)
                    dependency_keywords = ["import", "module", "dependency", "install", "backend", "not available"]
                    is_dependency_error = any(kw.lower() in error_msg.lower() for kw in dependency_keywords)

                    if is_dependency_error:
                        results[file_ext][strategy] = {"status": "DEPENDENCY_MISSING", "error": error_msg}
                        print(f"    â­ï¸  {strategy}: Skipped (missing dependency)")
                    else:
                        results[file_ext][strategy] = {"status": "ERROR", "error": error_msg}
                        print(f"    âŒ {strategy}: Error - {error_msg[:100]}")

        # Validation: Each file format should be successfully processed by at least one strategy
        for file_ext, format_results in results.items():
            successful_strategies = [s for s, r in format_results.items() if r["status"] == "SUCCESS"]
            assert len(successful_strategies) > 0, f"No strategies successfully processed {file_ext} files: {format_results}"

        # Special validation for .doc files if present
        if '.doc' in results:
            doc_results = results['.doc']

            # At least one core strategy should work with .doc files
            core_strategies = ["fixed_size", "sentence_based", "paragraph_based"]
            core_successes = [s for s in core_strategies if doc_results.get(s, {}).get("status") == "SUCCESS"]

            assert len(core_successes) > 0, f"No core strategies successfully processed .doc file: {doc_results}"
            print(f"    âœ… .doc file processed successfully by core strategies: {core_successes}")

    def test_adaptive_chunking(self):
        """Test adaptive chunking capabilities."""
        chunker = create_chunker("fixed_size", chunk_size=1000)

        # Test adaptation
        original_size = chunker.chunk_size

        # Test quality feedback
        chunker.adapt_parameters(0.3, "quality")
        assert chunker.chunk_size != original_size, "Chunker should adapt to feedback"

        # Test performance feedback
        chunker = create_chunker("fixed_size", chunk_size=1000)
        chunker.adapt_parameters(0.3, "performance")
        assert chunker.chunk_size != original_size, "Chunker should adapt to feedback"

    def test_streaming_interface(self):
        """Test streaming interface for large files."""
        test_file = self.test_data_dir / "sample_article.txt"
        if not test_file.exists():
            pytest.skip("Sample test file not found")

        # Create a streamable chunker
        try:
            from chunking_strategy.strategies.general.fixed_size import FixedSizeChunker
            chunker = FixedSizeChunker(chunk_size=500)

            # Test streaming
            def file_stream():
                with open(test_file, 'r') as f:
                    yield f.read()

            chunks = list(chunker.chunk_stream(file_stream()))
            assert len(chunks) > 0, "No chunks from streaming interface"

        except Exception as e:
            pytest.skip(f"Streaming test failed: {e}")

    def test_version_and_metadata(self):
        """Test version information and metadata."""
        assert __version__ is not None
        assert isinstance(__version__, str)
        assert len(__version__) > 0

        # Test chunker metadata
        chunkers = list_chunkers()
        for chunker_name in chunkers:
            try:
                from chunking_strategy.core.registry import get_chunker_metadata
                metadata = get_chunker_metadata(chunker_name)
                assert metadata is not None
                assert hasattr(metadata, 'name')
                assert metadata.name == chunker_name
            except Exception:
                # Some chunkers might not have full metadata
                pass


if __name__ == "__main__":
    pytest.main([__file__, "-v"])
